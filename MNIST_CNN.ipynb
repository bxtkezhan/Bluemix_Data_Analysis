{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lock seed\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(151 + i)\n",
    "    plt.title('num: {}'.format(np.argmax(mnist.train.labels[i])))\n",
    "    plt.axis('off')\n",
    "    plt.imshow((mnist.train.images[i].reshape(28, 28) * 255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_label_list = [np.sum(np.argmax(mnist.train.labels, 1) == num) for num in range(10)]\n",
    "num_labels = ['num: {}, count: {}'.format(num, num_label_list[num]) for num in range(10)]\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Train datasets distribution')\n",
    "plt.pie(num_label_list, explode=np.ones((10, )) * 0.05, labels=num_labels, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Config Model.\n",
    "\n",
    "learning_rate = 1.\n",
    "batch_size = 128\n",
    "n_epochs = 25\n",
    "\n",
    "input_dim = 784\n",
    "n_classes = 10\n",
    "dropout_rate = 0.75 # keep prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init placeholds.\n",
    "\n",
    "X = tf.placeholder('float32', shape=(None, input_dim))\n",
    "Y = tf.placeholder('float32', shape=(None, n_classes))\n",
    "keep_prob = tf.placeholder('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions.\n",
    "\n",
    "def conv2d(X, W, b):\n",
    "    conv = tf.nn.conv2d(X, W, strides=(1, 1, 1, 1), padding='VALID')\n",
    "    return tf.nn.bias_add(conv, b)\n",
    "\n",
    "def maxpool2d(X, k=2):\n",
    "    pool = tf.nn.max_pool(X, ksize=(1, k, k, 1), strides=(1, k, k, 1), padding='SAME')\n",
    "    return tf.nn.relu(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "\n",
    "def CNN(X, Weights, biases, dropout):\n",
    "    X = tf.reshape(X, shape=(-1, 28, 28, 1))\n",
    "    \n",
    "    conv1 = conv2d(X, Weights['W1'], biases['b1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    \n",
    "    conv2 = conv2d(conv1, Weights['W2'], biases['b2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    \n",
    "    fc1 = tf.reshape(conv2, shape=(-1, Weights['W3'].get_shape().as_list()[0]))\n",
    "    fc1 = tf.add(tf.matmul(fc1, Weights['W3']), biases['b3'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    out = tf.add(tf.matmul(fc1, Weights['W4']), biases['b4'])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Init Weights, biases\n",
    "Weights = {\n",
    "    'W1': tf.Variable(tf.random_normal((5, 5, 1, 10), stddev=0.1)),\n",
    "    'W2': tf.Variable(tf.random_normal((5, 5, 10, 20), stddev=0.1)),\n",
    "    'W3': tf.Variable(tf.random_normal((320, 128), stddev=0.1)),\n",
    "    'W4': tf.Variable(tf.random_normal((128, n_classes), stddev=0.1))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.constant(0.1, dtype='float32', shape=(10, ))),\n",
    "    'b2': tf.Variable(tf.constant(0.1, dtype='float32', shape=(20, ))),\n",
    "    'b3': tf.Variable(tf.constant(0.1, dtype='float32', shape=(128, ))),\n",
    "    'b4': tf.Variable(tf.constant(0.1, dtype='float32', shape=(10, )))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "pred = CNN(X, Weights, biases, keep_prob)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=Y))\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "currect_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(currect_pred, 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_list = [1]\n",
    "train_acc_list = [0]\n",
    "test_loss_list = [1]\n",
    "test_acc_list = [0]\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        times = mnist.train.num_examples // batch_size\n",
    "        for time in range(times):\n",
    "            batch_X, batch_Y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={X: batch_X, Y: batch_Y, keep_prob: dropout_rate})\n",
    "            _loss, _acc = sess.run(\n",
    "                [cost, accuracy],\n",
    "                feed_dict={X: batch_X, Y: batch_Y, keep_prob: 1.})\n",
    "            train_loss += _loss / times\n",
    "            train_acc += _acc / times\n",
    "        \n",
    "        test_loss, test_acc = 0., 0.\n",
    "        times = mnist.test.num_examples // 100\n",
    "        for time in range(times):\n",
    "            batch_X, batch_Y = mnist.test.next_batch(100)\n",
    "            _loss, _acc = sess.run(\n",
    "                [cost, accuracy],\n",
    "                feed_dict={X: batch_X, Y: batch_Y, keep_prob: 1.})\n",
    "            test_loss += _loss / times\n",
    "            test_acc += _acc / times\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_loss_list.append(test_loss)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('Epoch:', epoch + 1)\n",
    "        print('train loss = {}, train accracy = {}'.format(train_loss, train_acc))\n",
    "        print('test loss = {}, test accracy = {}'.format(test_loss, test_acc))\n",
    "        print('-' * 64)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Rate')\n",
    "    plt.plot(test_loss_list, '-b', label='test loss', linewidth=2)\n",
    "    plt.plot(test_acc_list, '-y', label='test accuracy', linewidth=2)\n",
    "    plt.plot(train_loss_list, '--r', label='train loss', linewidth=2)\n",
    "    plt.plot(train_acc_list, '--g', label='train accuracy', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
